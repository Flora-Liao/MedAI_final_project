{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558468e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import brier_score_loss, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "SEED = 42\n",
    "\n",
    "DATA_DIR = r'D:\\datasets_in_D\\Data_Science_for_Digital_Health\\BUSI_denoised\\processed'\n",
    "\n",
    "# below are the paths for cross-dataset training and testing\n",
    "# DATA_DIR_TRAIN_A = r'D:\\datasets_in_D\\Data_Science_for_Digital_Health\\BUS-NoCLAHE\\processed'\n",
    "# DATA_DIR_TRAIN_B = r'D:\\datasets_in_D\\Data_Science_for_Digital_Health\\QAMEBI_NoCLAHE\\processed'\n",
    "# DATA_DIR_TEST = r'D:\\datasets_in_D\\Data_Science_for_Digital_Health\\BUSI_pred_classify_ours\\processed'\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 1e-4\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ece16",
   "metadata": {},
   "source": [
    "### Fix random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8277d8",
   "metadata": {},
   "source": [
    "### Load and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3-channel\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5]),\n",
    "])\n",
    "\n",
    "# Load dataset (single dataset)\n",
    "full_ds = datasets.ImageFolder(DATA_DIR, transform=None)\n",
    "\n",
    "# === Uncomment below lines if you want to use cross-dataset training and testing ===\n",
    "# ds_a_raw = datasets.ImageFolder(DATA_DIR_TRAIN_A, transform=None)\n",
    "# ds_b_raw = datasets.ImageFolder(DATA_DIR_TRAIN_B, transform=None)\n",
    "# ds_test_raw = datasets.ImageFolder(DATA_DIR_TEST, transform=test_tfm)\n",
    "\n",
    "# full_train_val = torch.utils.data.ConcatDataset([ds_a_raw, ds_b_raw])\n",
    "# ===================================================================================\n",
    "\n",
    "# Single dataset\n",
    "# Split dataset\n",
    "g = torch.Generator().manual_seed(SEED)         # reproducible\n",
    "\n",
    "n = len(full_ds)\n",
    "n_train = int(TRAIN_RATIO * n)\n",
    "n_val   = int(VAL_RATIO * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(full_ds, [n_train, n_val, n_test], generator=g)\n",
    "train_ds.dataset.transform = train_tfm\n",
    "val_ds.dataset.transform   = test_tfm\n",
    "test_ds.dataset.transform  = test_tfm\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n",
    "\n",
    "# === Uncomment below lines if you want to use cross-dataset training and testing ===\n",
    "# n = len(full_train_val)\n",
    "# n_train = int(TRAIN_RATIO * n)\n",
    "# n_val   = n - n_train\n",
    "# train_ds, val_ds = random_split(full_train_val, [n_train, n_val], generator=g)\n",
    "\n",
    "# class SubsetWithTransform(torch.utils.data.Dataset):\n",
    "#     def __init__(self, subset, transform):\n",
    "#         self.subset = subset\n",
    "#         self.transform = transform\n",
    "#     def __len__(self):\n",
    "#         return len(self.subset)\n",
    "#     def __getitem__(self, idx):\n",
    "#         img, target = self.subset[idx]   # img is still PIL\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "#         return img, target\n",
    "\n",
    "# train_set = SubsetWithTransform(train_ds, train_tfm)\n",
    "# val_set   = SubsetWithTransform(val_ds,   test_tfm)   # deterministic\n",
    "# test_ds.dataset.transform  = test_tfm\n",
    "\n",
    "# Create data loaders\n",
    "# train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader   = DataLoader(val_set,   batch_size=BATCH_SIZE)\n",
    "# test_loader  = DataLoader(ds_test_raw,  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93ef3a",
   "metadata": {},
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(4096, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4f604",
   "metadata": {},
   "source": [
    "### Model fine-tuning & validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0796a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []\n",
    "val_preds_all, val_labels_all = [], []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).float().unsqueeze(1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).float().unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels).item()\n",
    "            val_loss += loss\n",
    "            running_val_loss += loss * images.size(0)\n",
    "\n",
    "            # Collect for calibration\n",
    "            val_preds_all.extend(outputs.cpu().numpy())\n",
    "            val_labels_all.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    print(f'Epoch [{epoch+1}/{EPOCH}], Validation Loss: {val_loss/len(val_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e894c",
   "metadata": {},
   "source": [
    "### Loss curves for train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f32f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(EPOCH), train_losses, label='Training Loss')\n",
    "plt.plot(range(EPOCH), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae86b66",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c02054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert predictions to binary labels\n",
    "threshold = 0.5\n",
    "binary_preds = [1 if pred >= threshold else 0 for pred in all_preds]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "precision = precision_score(all_labels, binary_preds)\n",
    "recall = recall_score(all_labels, binary_preds)\n",
    "f1 = f1_score(all_labels, binary_preds)\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, binary_preds).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall (Sensitivity): {recall:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'AUROC: {roc_auc:.4f}')\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(all_labels, binary_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee82ab",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metrics(y_true, y_probs, n_bootstraps=1000, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    metrics = {\n",
    "        'Accuracy': [],\n",
    "        'AUC': [],\n",
    "        'Sensitivity': [],\n",
    "        'Specificity': [],\n",
    "        'F1 score': [],\n",
    "        'Precision': []\n",
    "    }\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.choice(len(y_true), size=len(y_true), replace=True)\n",
    "        y_true_sample = y_true[indices]\n",
    "        y_probs_sample = y_probs[indices]\n",
    "        y_pred_sample = (y_probs_sample >= 0.5).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_sample, y_pred_sample).ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        metrics['Accuracy'].append(accuracy_score(y_true_sample, y_pred_sample))\n",
    "        metrics['AUC'].append(roc_auc_score(y_true_sample, y_probs_sample))\n",
    "        metrics['Sensitivity'].append(sensitivity)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "        metrics['F1 score'].append(f1_score(y_true_sample, y_pred_sample, zero_division=0))\n",
    "        metrics['Precision'].append(precision_score(y_true_sample, y_pred_sample, zero_division=0))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bootstrap\n",
    "boot_results = bootstrap_metrics(all_labels, all_preds)\n",
    "\n",
    "# Convert to DataFrame for plotting\n",
    "df_bootstrap = pd.DataFrame({k: v for k, v in boot_results.items()})\n",
    "\n",
    "# Convert to long-form DataFrame for seaborn boxplot\n",
    "df_melted = df_bootstrap.melt(var_name=\"Metric\", value_name=\"Values\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_melted, x=\"Metric\", y=\"Values\", palette=\"colorblind\")\n",
    "plt.title(\"Bootstrap Performance Metrics\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b6faf",
   "metadata": {},
   "source": [
    "### ROC and calibration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d552411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute calibration curve (bin-wise average confidence vs actual positive rate)\n",
    "prob_true, prob_pred = calibration_curve(all_labels, all_preds, n_bins=30)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve (Reliability Diagram)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7ed21",
   "metadata": {},
   "source": [
    "### Improve calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be353f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation predictions to NumPy arrays\n",
    "val_preds = np.array(val_preds_all).reshape(-1, 1)\n",
    "val_labels = np.array(val_labels_all).reshape(-1)\n",
    "\n",
    "# Logistic Regression (Platt scaling)\n",
    "lr = LogisticRegression()\n",
    "calibrator = CalibratedClassifierCV(estimator=lr, method='sigmoid', cv=5)\n",
    "calibrator.fit(val_preds, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3119da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_np = np.array(all_preds).reshape(-1, 1)\n",
    "calibrated_probs = calibrator.predict_proba(test_preds_np)[:, 1]  # Prob of class 1 (malignant)\n",
    "\n",
    "# Threshold at 0.5\n",
    "calibrated_binary = (calibrated_probs >= 0.5).astype(int)\n",
    "\n",
    "# Print metrics\n",
    "print(\"AUROC (calibrated):\", roc_auc_score(all_labels, calibrated_probs))\n",
    "print(\"Brier Score:\", brier_score_loss(all_labels, calibrated_probs))  # Lower is better\n",
    "print(\"Accuracy:\", accuracy_score(all_labels, calibrated_binary))\n",
    "print(\"Precision:\", precision_score(all_labels, calibrated_binary))\n",
    "print(\"Recall:\", recall_score(all_labels, calibrated_binary))\n",
    "print(\"F1 Score:\", f1_score(all_labels, calibrated_binary))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, calibrated_binary)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix (After Calibration)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(all_labels, calibrated_probs, n_bins=30)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibrated')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve (After Platt Scaling or Isotonic)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccb225",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5980636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 7.  Grad-CAM\n",
    "#     * Re-enable grads on the backbone\n",
    "# ------------------------------------------------------------------\n",
    "for p in model.features.parameters(): p.requires_grad_(True)\n",
    "\n",
    "# target_layers = [\n",
    "#     # model.features[16],     # conv3_3  (56×56)\n",
    "#     # model.features[23],     # conv4_3  (28×28)\n",
    "#     model.features[28]      # conv5_3  (14×14)\n",
    "# ]\n",
    "conv_layers = [m for m in model.features if isinstance(m, nn.Conv2d)]\n",
    "cam = GradCAM(model=model, target_layers=conv_layers)\n",
    "\n",
    "# take one test mini-batch (or loop, as you prefer)\n",
    "model.eval()\n",
    "imgs, labs = next(iter(test_loader))\n",
    "imgs = imgs.to(DEVICE)\n",
    "\n",
    "# forward once to get probabilities\n",
    "probs = model(imgs).cpu().detach().numpy().squeeze()\n",
    "\n",
    "# number of examples you want to display\n",
    "N_SHOW = 4\n",
    "THRESH = 0.5    # Set a threshold above 0.5 for displaying malignant cases\n",
    "showed = 0\n",
    "\n",
    "for i in range(len(probs)):\n",
    "    if probs[i] < THRESH:\n",
    "        continue\n",
    "    # a single image tensor\n",
    "    inp = imgs[i:i+1].requires_grad_(True)\n",
    "\n",
    "    # run Grad-CAM → 2-D map in [0,1]\n",
    "    grayscale_cam = cam(\n",
    "        input_tensor=inp,\n",
    "        targets=[ClassifierOutputTarget(0)])  # class-0 = malignant\n",
    "    grayscale_cam = grayscale_cam[0]         # (H,W)\n",
    "\n",
    "    # --- build a 'jet' heat-map -------------------------------------------\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    # original image back to [0,1] RGB for display\n",
    "    rgb = inp[0].cpu().detach().numpy().transpose(1, 2, 0)       # C,H,W → H,W,C\n",
    "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
    "\n",
    "    overlay = 0.4 * heatmap + 0.6 * rgb                  # blend\n",
    "    overlay = np.clip(overlay, 0., 1.)\n",
    "\n",
    "    # --- side-by-side plot -------------------------------------------------\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    ax[0].imshow(rgb)\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(overlay)\n",
    "    ax[1].set_title(f\"CAM - jet  |  p={probs[i]:.2f}\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "    showed += 1\n",
    "    if showed >= N_SHOW:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience_DigitalHealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
